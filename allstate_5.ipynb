{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allstate week 5\n",
    "\n",
    "There are a couple of new foundings that I'd like to share with you:\n",
    "\n",
    "1. Two-way interactions of categorical features\n",
    "2. Official LightGBM Python wrapper - 4x faster than XGBoost\n",
    "3. Additional tuning tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, pipeline, metrics, grid_search, cross_validation\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from scipy import sparse\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_mae(labels,preds,lift=200):\n",
    "    return mean_absolute_error(np.exp(labels)-lift, np.exp(preds)-lift)\n",
    "\n",
    "def logregobj(labels, preds):\n",
    "    con = 2\n",
    "    x =preds-labels\n",
    "    grad =con*x / (np.abs(x)+con)\n",
    "    hess =con**2 / (np.abs(x)+con)**2\n",
    "    return grad, hess \n",
    "\n",
    "\n",
    "log_mae_scorer = metrics.make_scorer(log_mae, greater_is_better = False)\n",
    "\n",
    "def search_model(train_x, train_y, est, param_grid, n_jobs, cv, refit=False):\n",
    "##Grid Search for the best model\n",
    "    model = grid_search.GridSearchCV(estimator  = est,\n",
    "                                     param_grid = param_grid,\n",
    "                                     scoring    = log_mae_scorer,\n",
    "                                     verbose    = 10,\n",
    "                                     n_jobs  = n_jobs,\n",
    "                                     iid        = True,\n",
    "                                     refit    = refit,\n",
    "                                     cv      = cv)\n",
    "    # Fit Grid Search Model\n",
    "    model.fit(train_x, train_y)\n",
    "    print(\"Best score: %0.3f\" % model.best_score_)\n",
    "    print(\"Best parameters set:\", model.best_params_)\n",
    "    print(\"Scores:\", model.grid_scores_)\n",
    "    return model\n",
    "\n",
    "def xg_eval_mae(yhat, dtrain, lift=200):\n",
    "    y = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(y)-lift, np.exp(yhat)-lift)\n",
    "\n",
    "def xgb_logregobj(preds, dtrain):\n",
    "    con = 2\n",
    "    labels = dtrain.get_label()\n",
    "    x =preds-labels\n",
    "    grad =con*x / (np.abs(x)+con)\n",
    "    hess =con**2 / (np.abs(x)+con)**2\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "def search_model_mae (train_x, train_y, est, param_grid, n_jobs, cv, refit=False):\n",
    "##Grid Search for the best model\n",
    "    model = grid_search.GridSearchCV(estimator  = est,\n",
    "                                     param_grid = param_grid,\n",
    "                                     scoring    = 'neg_mean_absolute_error',\n",
    "                                     verbose    = 10,\n",
    "                                     n_jobs  = n_jobs,\n",
    "                                     iid        = True,\n",
    "                                     refit    = refit,\n",
    "                                     cv      = cv)\n",
    "    # Fit Grid Search Model\n",
    "    model.fit(train_x, train_y)\n",
    "    print(\"Best score: %0.3f\" % model.best_score_)\n",
    "    print(\"Best parameters set:\", model.best_params_)\n",
    "    print(\"Scores:\", model.grid_scores_)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "def xgb_blend(estimators, train_x, train_y, test_x, fold, early_stopping_rounds=0):\n",
    "    print (\"Blend %d estimators for %d folds\" % (len(estimators), fold))\n",
    "    skf = list(KFold(len(train_y), fold))\n",
    "    \n",
    "    train_blend_x = np.zeros((train_x.shape[0], len(estimators)))\n",
    "    test_blend_x = np.zeros((test_x.shape[0], len(estimators)))\n",
    "    scores = np.zeros ((len(skf),len(estimators)))\n",
    "    best_rounds = np.zeros ((len(skf),len(estimators)))\n",
    "    \n",
    "\n",
    "    \n",
    "    for j, est in enumerate(estimators):\n",
    "        print (\"Model %d: %s\" %(j+1, est))\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], len(skf)))\n",
    "        for i, (train, val) in enumerate(skf):\n",
    "            print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x[train]\n",
    "            train_y_fold = train_y[train]\n",
    "            val_x_fold = train_x[val]\n",
    "            val_y_fold = train_y[val]\n",
    "            if early_stopping_rounds==0: # without early stopping\n",
    "                est.fit(train_x_fold, train_y_fold)\n",
    "                best_rounds[i,j]=est.n_estimators\n",
    "                val_y_predict_fold = est.predict(val_x_fold)\n",
    "                score = log_mae(val_y_fold, val_y_predict_fold,200)\n",
    "                print (\"Score: \", score)\n",
    "                scores[i,j]=score\n",
    "                train_blend_x[val, j] = val_y_predict_fold\n",
    "                test_blend_x_j[:,i] = est.predict(test_x)\n",
    "                print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))\n",
    "            else:                        # early stopping\n",
    "                est.set_params( n_estimators=10000)\n",
    "                est.fit(train_x_fold,\n",
    "                        train_y_fold,\n",
    "                        eval_set=[(val_x_fold, val_y_fold)],\n",
    "                        eval_metric=xg_eval_mae,\n",
    "                        early_stopping_rounds=early_stopping_rounds,\n",
    "                        verbose=False\n",
    "                       )\n",
    "                best_round=est.best_iteration\n",
    "                best_rounds[i,j]=best_round\n",
    "                print (\"best round %d\" % (best_round))\n",
    "                val_y_predict_fold = est.predict(val_x_fold,ntree_limit=best_round)\n",
    "                score = log_mae(val_y_fold, val_y_predict_fold,200)\n",
    "                print (\"Score: \", score)\n",
    "                scores[i,j]=score\n",
    "                train_blend_x[val, j] = val_y_predict_fold\n",
    "                test_blend_x_j[:,i] = est.predict(test_x,ntree_limit=best_round)\n",
    "                print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))            \n",
    "   \n",
    "        test_blend_x[:,j] = test_blend_x_j.mean(1)\n",
    "        print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    print (\"Score for blended models is %f\" % (np.mean(scores)))\n",
    "    return (train_blend_x, test_blend_x, scores,best_rounds )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM official Python Wrapper\n",
    "\n",
    "last week Microsoft released the official Python Wrapper for LightGBM. Following are the key benifit:\n",
    "\n",
    "* Scikit-learn style API\n",
    "* No need to dump training data into disk (as opposed to the pyLightGBM wrapper we used before). As a result, you can expect a huge improvement on speed - at least 4X faster than XGBoost\n",
    "* Support sparse matrix\n",
    "* Support custom objective function and metric. You can used log-trainsformed MAE for training now!\n",
    "* Native cross validation function makes validation much easier\n",
    "\n",
    "\n",
    "https://github.com/Microsoft/LightGBM/tree/master/python-package\n",
    "\n",
    "#### Installation guide:\n",
    "\n",
    "Following Installation Guide to build first. \n",
    "\n",
    "For windows users, please change the build config to DLL.\n",
    "\n",
    "Install with cd python-package; python setup.py install\n",
    "Note: Make sure you have setuptools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are the updated utitily functions based on official wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "def lgbm_eval_mae(yhat, dtrain, lift=200):\n",
    "    y = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(y)-lift, np.exp(yhat)-lift), False\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "def lgbm_blend(estimators, train_x, train_y, test_x, fold, early_stopping_rounds=0):\n",
    "    print (\"Blend %d estimators for %d folds\" % (len(estimators), fold))\n",
    "    skf = list(KFold(len(train_y), fold))\n",
    "    \n",
    "    train_blend_x = np.zeros((train_x.shape[0], len(estimators)))\n",
    "    test_blend_x = np.zeros((test_x.shape[0], len(estimators)))\n",
    "    scores = np.zeros ((len(skf),len(estimators)))\n",
    "    best_rounds = np.zeros ((len(skf),len(estimators)))\n",
    "    \n",
    "\n",
    "    \n",
    "    for j, est in enumerate(estimators):\n",
    "        print (\"Model %d: %s\" %(j+1, est))\n",
    "        test_blend_x_j = np.zeros((test_x.shape[0], len(skf)))\n",
    "        for i, (train, val) in enumerate(skf):\n",
    "            print (\"Model %d fold %d\" %(j+1,i+1))\n",
    "            fold_start = time.time() \n",
    "            train_x_fold = train_x[train]\n",
    "            train_y_fold = train_y[train]\n",
    "            val_x_fold = train_x[val]\n",
    "            val_y_fold = train_y[val]\n",
    "            if early_stopping_rounds==0: # without early stopping\n",
    "                est.fit(train_x_fold, train_y_fold)\n",
    "                best_rounds[i,j]=est.n_estimators\n",
    "                val_y_predict_fold = est.predict(val_x_fold)\n",
    "                score = log_mae(val_y_fold, val_y_predict_fold,200)\n",
    "                print (\"Score: \", score)\n",
    "                scores[i,j]=score\n",
    "                train_blend_x[val, j] = val_y_predict_fold\n",
    "                test_blend_x_j[:,i] = est.predict(test_x)\n",
    "                print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))\n",
    "            else:                        # early stopping\n",
    "                est.set_params( n_estimators=100000)\n",
    "                est.fit(train_x_fold,\n",
    "                        train_y_fold,\n",
    "                        eval_set=[(val_x_fold, val_y_fold)],\n",
    "                        eval_metric=lgbm_eval_mae,\n",
    "                        early_stopping_rounds=early_stopping_rounds,\n",
    "                        verbose=False\n",
    "                       )\n",
    "                best_round=est.best_iteration\n",
    "                best_rounds[i,j]=best_round\n",
    "                print (\"best round %d\" % (best_round))\n",
    "                val_y_predict_fold = est.predict(val_x_fold,num_iteration=best_round)\n",
    "                score = log_mae(val_y_fold, val_y_predict_fold,200)\n",
    "                print (\"Score: \", score)\n",
    "                scores[i,j]=score\n",
    "                train_blend_x[val, j] = val_y_predict_fold\n",
    "                test_blend_x_j[:,i] = est.predict(test_x,num_iteration=best_round)\n",
    "                print (\"Model %d fold %d fitting finished in %0.3fs\" % (j+1,i+1, time.time() - fold_start))            \n",
    "   \n",
    "        test_blend_x[:,j] = test_blend_x_j.mean(1)\n",
    "        print (\"Score for model %d is %f\" % (j+1,np.mean(scores[:,j])))\n",
    "    print (\"Score for blended models is %f\" % (np.mean(scores)))\n",
    "    return (train_blend_x, test_blend_x, scores,best_rounds )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "start = time.time() \n",
    "train_data = pd.read_csv('../input/train.csv')\n",
    "train_size=train_data.shape[0]\n",
    "print (\"Loading train data finished in %0.3fs\" % (time.time() - start))        \n",
    "\n",
    "test_data = pd.read_csv('../input/test.csv')\n",
    "print (\"Loading test data finished in %0.3fs\" % (time.time() - start))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge train and test\n",
    "\n",
    "This will save our time on duplicating logics for train and test and will also ensure the transformations applied on train and test are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_data=pd.concat([train_data\n",
    "                       ,test_data])\n",
    "del( train_data, test_data)\n",
    "print (\"Full Data set created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group features\n",
    "\n",
    "In this step we will group the features into different groups so we can preprocess them seperately afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_types = full_data.dtypes  \n",
    "cat_cols = list(data_types[data_types=='object'].index)\n",
    "num_cols = list(data_types[data_types=='int64'].index) + list(data_types[data_types=='float64'].index)\n",
    "\n",
    "id_col = 'id'\n",
    "target_col = 'loss'\n",
    "num_cols.remove('id')\n",
    "num_cols.remove('loss')\n",
    "\n",
    "print (\"Categorical features:\", cat_cols)\n",
    "print ( \"Numerica features:\", num_cols)\n",
    "print ( \"ID: %s, target: %s\" %( id_col, target_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical features \n",
    "### 1. Label Encoding (Factorizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LBL = preprocessing.LabelEncoder()\n",
    "start=time.time()\n",
    "for cat_col in cat_cols:\n",
    "#     print (\"Factorize feature %s\" % (cat))\n",
    "    full_data[cat_col] = LBL.fit_transform(full_data[cat_col])\n",
    "print ('Label enconding finished in %f seconds' % (time.time()-start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New: Two-way interactions for categorical features\n",
    "\n",
    "The idea was borrowed from a kernel script from Kaggle forum and I made following changes to make it run faster and more accurate:\n",
    "\n",
    "1. Instead of decoding the interactions in a lexical way, I simply concatenated each pair of features and apply label-encoding on them. It ended up with very similar results as the original script but way faster and more memory efficient.\n",
    "\n",
    "2. Added four features to the list which appeared to be effective. Here are some tips if you want to explore more possibilities:\n",
    "    * Train a model use original features (no interaction)\n",
    "    * Count distinct values of each feature\n",
    "    * Observe the distribution of combination features used in the original script by feature importance and value count.\n",
    "        * Mean count of values: 3.64,max:17, min:2 which indicates low cardinality features are prefered.\n",
    "        * Mean feature importance: \n",
    "        * It seems low cardinality features (value counts 2 to 4), and midium important features are prefered.\n",
    "        * There's a high correlation between feature number and value counts (cont77-88). Could it be useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# feature name\timportance\tcount\tis in comb\n",
    "#  cat1\t1022\t2\tTRUE\n",
    "#  cat10\t519\t2\tTRUE\n",
    "#  cat100\t4301\t15\t\n",
    "#  cat101\t2474\t19\t\n",
    "#  cat102\t767\t9\t\n",
    "#  cat103\t1693\t14\tTRUE\n",
    "#  cat104\t380\t17\t\n",
    "#  cat105\t879\t20\t\n",
    "#  cat106\t489\t18\t\n",
    "#  cat107\t1055\t20\t\n",
    "#  cat108\t628\t11\t\n",
    "#  cat109\t618\t85\t\n",
    "#  cat11\t270\t2\tTRUE\n",
    "#  cat110\t2764\t134\t\n",
    "#  cat111\t1665\t17\tTRUE\n",
    "#  cat112\t4425\t51\t\n",
    "#  cat113\t1834\t63\t\n",
    "#  cat114\t1962\t19\t\n",
    "#  cat115\t645\t23\t\n",
    "#  cat116\t1466\t349\t\n",
    "#  cat12\t310\t2\tTRUE\n",
    "#  cat13\t217\t2\tTRUE\n",
    "#  cat14\t98\t2\tTRUE\n",
    "#  cat15\t2\t2\t\n",
    "#  cat16\t133\t2\tTRUE\n",
    "#  cat17\t74\t2\t\n",
    "#  cat18\t92\t2\t\n",
    "#  cat19\t114\t2\t\n",
    "#  cat20\t23\t2\t\n",
    "#  cat21\t69\t2\t\n",
    "#  cat22\t28\t2\t\n",
    "#  cat23\t352\t2\tTRUE\n",
    "#  cat24\t181\t2\tTRUE\n",
    "#  cat25\t272\t2\tTRUE\n",
    "#  cat26\t226\t2\t\n",
    "#  cat27\t372\t2\t\n",
    "#  cat28\t208\t2\tTRUE\n",
    "#  cat29\t196\t2\t\n",
    "#  cat3\t144\t2\tTRUE\n",
    "#  cat30\t157\t2\t\n",
    "#  cat31\t218\t2\t\n",
    "#  cat32\t56\t2\t\n",
    "#  cat33\t54\t2\t\n",
    "#  cat34\t26\t2\t\n",
    "#  cat35\t14\t2\t\n",
    "#  cat36\t375\t2\tTRUE\n",
    "#  cat37\t395\t2\t\n",
    "#  cat38\t309\t2\tTRUE\n",
    "#  cat39\t219\t2\t\n",
    "#  cat40\t175\t2\tTRUE\n",
    "#  cat41\t168\t2\t\n",
    "#  cat42\t66\t2\t\n",
    "#  cat43\t173\t2\t\n",
    "#  cat44\t292\t2\t\n",
    "#  cat45\t154\t2\t\n",
    "#  cat46\t41\t2\t\n",
    "#  cat47\t27\t2\t\n",
    "#  cat48\t29\t2\t\n",
    "#  cat49\t233\t2\t\n",
    "#  cat50\t328\t2\tTRUE\n",
    "#  cat51\t77\t2\t\n",
    "#  cat52\t243\t2\t\n",
    "#  cat53\t343\t2\t\n",
    "#  cat54\t196\t2\t\n",
    "#  cat55\t11\t2\t\n",
    "#  cat56\t17\t2\t\n",
    "#  cat57\t168\t2\tTRUE\n",
    "#  cat58\t24\t2\t\n",
    "#  cat59\t39\t2\t\n",
    "#  cat60\t41\t2\t\n",
    "#  cat61\t65\t2\t\n",
    "#  cat62\t8\t2\t\n",
    "#  cat63\t22\t2\t\n",
    "#  cat64\t1]]\t2\t\n",
    "#  cat65\t94\t2\t\n",
    "#  cat66\t215\t2\t\n",
    "#  cat67\t58\t2\t\n",
    "#  cat68\t28\t2\t\n",
    "#  cat69\t16\t2\t\n",
    "#  cat7\t64\t2\tTRUE\n",
    "#  cat70\t7\t2\t\n",
    "#  cat71\t107\t2\t\n",
    "#  cat72\t848\t2\tTRUE\n",
    "#  cat73\t746\t3\tTRUE\n",
    "#  cat74\t192\t3\t\n",
    "#  cat75\t568\t3\t\n",
    "#  cat76\t209\t3\tTRUE\n",
    "#  cat77\t88\t4\t\n",
    "#  cat78\t116\t4\t\n",
    "#  cat79\t970\t4\tTRUE\n",
    "#  cat80\t997\t4\tTRUE\n",
    "#  cat81\t1004\t4\tTRUE\n",
    "#  cat82\t1111\t4\tTRUE\n",
    "#  cat83\t1227\t4\t\n",
    "#  cat84\t765\t4\t\n",
    "#  cat85\t136\t4\t\n",
    "#  cat86\t37\t4\t\n",
    "#  cat87\t497\t4\tTRUE\n",
    "#  cat88\t122\t4\t\n",
    "#  cat89\t8\t9\tTRUE\n",
    "#  cat9\t323\t2\tTRUE\n",
    "#  cat90\t34\t7\tTRUE\n",
    "#  cat91\t1198\t8\t\n",
    "#  cat92\t384\t9\t\n",
    "#  cat93\t816\t5\t\n",
    "#  cat94\t459\t7\t\n",
    "#  cat95\t392\t5\t\n",
    "#  cat96\t258\t9\t\n",
    "#  cat97\t387\t7\t\n",
    "#  cat98\t163\t5\t\n",
    "#  cat99\t263\t17\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LBL = preprocessing.LabelEncoder()\n",
    "start=time.time()\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Original combination features\n",
    "comb_list = ['cat80', 'cat87', 'cat57', 'cat12', 'cat79', 'cat10', 'cat7', 'cat89', 'cat2', 'cat72', 'cat81', 'cat11', 'cat1', 'cat13', 'cat9', 'cat3', 'cat16', 'cat90', 'cat23', 'cat36', 'cat73', 'cat103', 'cat40', 'cat28', 'cat111', 'cat6', 'cat76', 'cat50', 'cat5', 'cat4', 'cat14', 'cat38', 'cat24', 'cat82', 'cat25']\n",
    "# Added 'cat37','cat27','cat53','cat44'\n",
    "comb_list = ['cat37','cat27','cat53','cat44'] + comb_list\n",
    "comb_two_cols = [] \n",
    "for comb in itertools.combinations(comb_list, 2):\n",
    "    comb_col_name = comb[0] + comb[1]\n",
    "    print (comb_col_name)\n",
    "    full_data [comb_col_name] = LBL.fit_transform(full_data [ comb[0]] + full_data [ comb[1]])\n",
    "    comb_two_cols.append(comb_col_name)\n",
    "    \n",
    "print ('Label enconding finished in %f seconds' % (time.time()-start))\n",
    "\n",
    "print (full_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. One Hot Encoding (get dummies)\n",
    "\n",
    "OHE can be done by either Pandas' get_dummies() or SK Learn's OneHotEncoder. \n",
    "\n",
    "* get_dummies is easier to implement (can be used directly on raw categorical features, i.e. strings, but it takes longer time and is not memory efficient.\n",
    "\n",
    "* OneHotEncoder requires the features being converted to numeric, which has already been done by LabelEncoder in previous step, and is much more efficient (4x faster at least).\n",
    "\n",
    "* We will convert the OHE's results to a sparse matrix which uses way less memory as compared to dense matrix. However, not all algorithms and packagers support sparse matrix, e.g. Keras. In that case, we'll need to use other tricks to make it work.\n",
    "\n",
    "\n",
    "## Note: due to the large number of newly added two-way features, the memory usage can easily excceed 10G if you want to run OHE, which, however, is optional so I just commented it out. Feel free to uncomment it if you'd like to give it a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OHE = preprocessing.OneHotEncoder(sparse=True)\n",
    "# start=time.time()\n",
    "# full_data_sparse=OHE.fit_transform(full_data[cat_cols+comb_two_cols])\n",
    "# print ('One-hot-encoding finished in %f seconds' % (time.time()-start))\n",
    "\n",
    "# print (full_data_sparse.shape)\n",
    "\n",
    "# ## it should be (313864, 1176)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Leave-one-out Encoding\n",
    "\n",
    "This is a very useful trick that has been used by many Kaggle winning solutions. It's particularly effective for high cardinality categorical features, postal code for instance. However, it doesn't seem to help a lot for this competition and the following code is just FYI. Feel free to skip it as it may take long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start=time.time()\n",
    "# loo_cols =[]\n",
    "# for col in cat_cols:\n",
    "#     print (\"Leave-One-Out Encoding  %s\" % (col))\n",
    "#     print (\"Leave-one-out encoding column %s for %s......\" % (col, target_col))\n",
    "#     aggr=full_data.groupby(col)[target_col].agg([np.mean]).join(full_data[:train_size].groupby(col)[target_col].agg([np.sum,np.size]),how='left')        \n",
    "#     meanTagetAggr = np.mean(aggr['mean'].values)\n",
    "#     aggr=full_data.join(aggr,how='left', on=col)[list(aggr.columns)+[target_col]]\n",
    "#     loo_col = 'MEAN_BY_'+col+'_'+target_col\n",
    "#     full_data[loo_col] = \\\n",
    "#     aggr.apply(lambda row: row['mean'] if math.isnan(row[target_col]) \n",
    "#                                                        else (row['sum']-row[target_col])/(row['size']-1)*random.uniform(0.95, 1.05) , axis=1)\n",
    "#     loo_cols.append(loo_col)\n",
    "#     print (\"New feature %s created.\" % (loo_col))\n",
    "# print ('Leave-one-out enconding finished in %f seconds' % (time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric features\n",
    "\n",
    "We will apply two preprocessings on numeric features:\n",
    "\n",
    "1. Apply box-cox transformations for skewed numeric features.\n",
    "\n",
    "2. Scale numeric features so they will fall in the range between 0 and 1.\n",
    "\n",
    "Please be advised that these preprocessings are not necessary for tree-based models, e.g. XGBoost. However, linear or linear-based models, which will be dicussed in following weeks, may benefit from them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate skewness of each numeric features: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skew, boxcox\n",
    "skewed_cols = full_data[num_cols].apply(lambda x: skew(x.dropna()))\n",
    "print (skewed_cols.sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Apply box-cox transformations: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skewed_cols = skewed_cols[skewed_cols > 0.25].index.values\n",
    "for skewed_col in skewed_cols:\n",
    "    full_data[skewed_col], lam = boxcox(full_data[skewed_col] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Apply Standard Scaling:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SSL = preprocessing.StandardScaler()\n",
    "for num_col in num_cols:\n",
    "    full_data[num_col] = SSL.fit_transform(full_data[num_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: LBL and OHE are likely exclusive so we will use one of them at a time combined with numeric features. In the following steps we will use OHE + Numeric to tune XGBoost models and you can apply the same process with OHE + Numeric features. Averaging results from two different models will likely generate better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Numberic features + Label Encoded Categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LE + LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New: updated LightGBM blending\n",
    "\n",
    "Note: 10 folds appear to be much bettern than 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## start = time.time()\n",
    "estimators = [lgb.LGBMRegressor(learning_rate=0.005,                             \n",
    "                     n_estimators=100000,\n",
    "                     max_bin=255,\n",
    "                     num_leaves=70,\n",
    "                     min_child_samples=230,\n",
    "                     colsample_bytree=0.3,\n",
    "                     subsample=0.9,\n",
    "                     subsample_freq=1,\n",
    "                     reg_alpha=0.003,\n",
    "                     silent=False),\n",
    "              lgb.LGBMRegressor(learning_rate=0.005,                              \n",
    "                     n_estimators=100000,\n",
    "                     max_bin=255,\n",
    "                     num_leaves=70,\n",
    "                     min_child_samples=230,\n",
    "                     colsample_bytree=0.25,\n",
    "                     subsample=0.9,\n",
    "                     subsample_freq=1,\n",
    "                     reg_alpha=0.003,\n",
    "                     silent=False)\n",
    "              ]\n",
    "(train_blend_x_gbm_le11,\n",
    " test_blend_x_gbm_le11,\n",
    " blend_scores_gbm_le11,\n",
    " best_rounds_gbm_le11) = lgbm_blend(estimators, train_x, train_y, test_x,\n",
    "                                 10, ## 10 folds appear to be much better than 4\n",
    "                                 1000)\n",
    "\n",
    "print (np.mean(blend_scores_gbm_le1,axis=0))\n",
    "print (np.mean(best_rounds_gbm_le1,axis=0))\n",
    "np.savetxt(\"../input/train_blend_x_gbm_le1.csv\",train_blend_x_gbm_le1, delimiter=\",\")\n",
    "np.savetxt(\"../input/test_blend_x_gbm_le1.csv\",test_blend_x_gbm_le1, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LE + XGBoost\n",
    "\n",
    "1. As quite a lot new features were added, colsample_bytree needs to be adjusted to a much smaller number.\n",
    "2. 10 folds tends to be much bettern than 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimators = [xgb.XGBRegressor(objective=logregobj,\n",
    "                              learning_rate=0.01,\n",
    "                              n_estimators=100000,\n",
    "                              max_depth=,\n",
    "                              min_child_weight=,\n",
    "                              colsample_bytree=,\n",
    "                              subsample=,\n",
    "                              gamma=,\n",
    "                              nthread=-1,\n",
    "                              silent=True,\n",
    "                              seed=1234\n",
    "                             )\n",
    "              ]\n",
    "\n",
    "(train_blend_x_xgb_le,\n",
    " test_blend_x_xgb_le,\n",
    " blend_scores_xgb_le,\n",
    " best_rounds_xgb_le) = xgb_blend(estimators, \n",
    "                                      train_x, \n",
    "                                      train_y, \n",
    "                                      test_x,\n",
    "                                      10,\n",
    "                                      500)\n",
    "\n",
    "print (np.mean(blend_scores_xgb_le,axis=0))\n",
    "print (np.mean(best_rounds_xgb_le,axis=0))\n",
    "np.savetxt(\"../input/train_blend_x_xgb_le.csv\",train_blend_x_xgb_le, delimiter=\",\")\n",
    "np.savetxt(\"../input/test_blend_x_xgb_le.csv\",test_blend_x_xgb_le, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lift = 200\n",
    "\n",
    "full_data_sparse = sparse.hstack((full_data_sparse\n",
    "                                  ,full_data[num_cols])\n",
    "                                 , format='csr'\n",
    "                                 )\n",
    "print (full_data_sparse.shape)\n",
    "train_x = full_data_sparse[:train_size]\n",
    "test_x = full_data_sparse[train_size:]\n",
    "train_y = np.log(full_data[:train_size].loss.values + lift)\n",
    "ID = full_data.id[:train_size].values\n",
    "\n",
    "xgtrain = xgb.DMatrix(train_x, label=train_y,missing=np.nan) #used for Bayersian Optimization\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_x, train_y, train_size=.80, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following section didn't change except:\n",
    "\n",
    "1. use 10 folds instead of 4\n",
    "2. XGB linear appears to be time consuming and doesn't help a lot. So feel free to skip it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OHE + LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OHE +XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OHE + MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "1. Added two-way feature interactions\n",
    "2. Use smaller colsample_by_tree (less than 0.1)\n",
    "3. Use 10 folds instead of 5 for blending"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
